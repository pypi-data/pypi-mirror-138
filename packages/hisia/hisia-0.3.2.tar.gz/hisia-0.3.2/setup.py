# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['hisia', 'hisia.models']

package_data = \
{'': ['*'], 'hisia': ['visualization/*'], 'hisia.models': ['data/*']}

install_requires = \
['dill==0.3.4',
 'lemmy>=2.1.0,<3.0.0',
 'loguru>=0.5.0,<0.6.0',
 'matplotlib>=3.2.1,<4.0.0',
 'pandas>=1.0.3,<2.0.0',
 'scikit-learn==1.0.2']

setup_kwargs = {
    'name': 'hisia',
    'version': '0.3.2',
    'description': 'A Danish sentiment analysis using scikit-learn',
    'long_description': 'Hisia\n==============================\n\n:blush: :smiley: :relaxed: :yum: :wink: :smirk: :flushed: :worried: :frowning: :triumph: :disappointed: :angry: :persevere: :confounded: :shit: \n\n\nA Danish sentiment analyzer using scikit-learn LogisticRegression\n\n![hisia cover](cover_image.png)\n\n```python\nfrom hisia import Hisia\n\nnegative_joe = Hisia(\'Det er simpelthen ikke okay :(\')\nnegative_joe.sentiment\n# from hisia import Hisia\n\nnegative_joe = Hisia(\'Det er simpelthen ikke okay :(\')\nnegative_joe.sentiment\n# Sentiment(sentiment=\'negative\', positive_probability=0.008, negative_probability=0.992)\nnegative_joe.explain\n# {\'decision\': -4.8335798389992055,\n#  \'intercept\': 0.809727254639209,\n#  \'features\': {(\':(\', -4.36432604514099),\n#               (\'ikke\', -3.273671001915033),\n#               (\'simpelthen\', -2.450742871314483),\n#               (\'simpelthen ikke\', -1.9214388345665114)}\n# }\n\npositive_gro = Hisia(\'Det var ikke dårligt\')\npositive_gro\n# Sentiment(sentiment=positive, positive_probability=0.684, negative_probability=0.316)\npositive_gro.explain\n# {\'decision\': 0.7739625583753332,\n#  \'intercept\': 0.809727254639209,\n#  \'features\': {(\'dårlig\', -8.910130726393785),\n#              (\'ikke\', -3.273671001915033),\n#              (\'ikke dårlig\', 5.126914312204595)}\n# }\n\n```\n### Hisia (Emotions)\n_Hisia_ is a Swahili word for emotion/feeling. My initial thought was to call it _Følelser_, a Danish word for feeling but it was just not right. As a Tanzanian, I went with Swahili as it was much more of a package name I would like to install from PyPI. :) \n\n```bash\npip install -U hisia\n```\n\n### Data and Models Used in Hisia\n\n**Data:** 2016 TrustPilot\'s 254,464 Danish reviews\' body and stars and [8 fake reviews]*20 see notes for the explanation.<br>\n&ensp; _Update_: 2021-10-02: Political Data from [Sentiment Analysis on Comments from Danish Political Articles on Social Media](https://github.com/steffan267/Sentiment-Analysis-on-Danish-Social-Media)\n\n**Models**<br>\nHisia, _LogisticRegression_ with SAGA, a variant of Stochastic Average Gradient (SAG), as a solver, L2 penalty was select for the base model. Test score **accuracy is ca. 93%** and **recall of 93%**. SAGA was selected because it is a faster solver for large datasets (rows and columns wise). As a stochastic gradient, the the memory of the previous epoch gradient is incorporated/feed-forward to the current epoch. This allows a faster convergence rate. Seeds: 42 in data split of 80% training, 20% test, and 42 in the model used for reproducibility. Check notebooks for other parameters.\n\nHisiaTrain, _SGDClassifier_, Stochastic Gradient Descent learner with smooth loss \'modified_huber as loss function and L2 penalty. Test score **accuracy 94%** and **recall of 94%**. SGDClassifier was select because of partial_fit. It allows batch/online training.\n\n**Note:** This score reflects models in regards to TrustPilot reviews style of writing.<br>\n > 8x20 fake reviews. TrustPilot reviews are directed towards products and services. A word like \'elsker\'(love) or \'hader\'(hate) were rare. To make sure the model learns such a relationship, I added 8 reviews and duplicated them 20 times. These new sentences did not increase or decrease the model accuracy but correctly added the coefficient of the words love, hate and not bad (ikke dårligt). \n\nNotebook folder contains playground [model_train notebook](https://github.com/Proteusiq/hisia/blob/master/notebooks/model_training.ipynb) to reproduce the model scores and also explore what the model has learned. Same parameters and data used to train Hisia.\n\n\n# News & Updates\n\nHisia is part of [sprogteknologi.dk](https://sprogteknologi.dk/dataset/hisia) tools\nComparing [Afinn (Lexicon) and Hisia (Logistic Regression)](https://github.com/Proteusiq/hisia/blob/master/notebooks/afinn_hisia_comparison.ipynb) scoring models\n\n\nFeatures\n--------\n- Sentiment analysis\n- Sentiment explainer\n- Sentiment reinforcement learning (Coming Soon)\n- Sentiment retrainer (Coming Soon)\n\n\n\nProject Organization\n------------\n\n    ├── LICENSE\n    ├── README.md         \n    │\n    ├── notebooks          <-  Jupyter notebook. Reproduce the results, show model explanations, and comparing with afinn\n    │   └── model_training.ipynb\n    │   └── afinn_hisia_comparison.ipynb\n    │   └── helpers.py          \n    │                         \n    │\n    ├── hisia              <-   Source code for use in this project.\n    │\xa0\xa0 ├── __init__.py    <-   Makes hisia a Python module\n    │\xa0\xa0 ├── hisia.py       <-   hisia a sentiment predictor and explainer\n    │   │\n    │\xa0\xa0 ├── data           <-  Path to training and validating dataset and stopwords: data folder is inside hisia for retrain\n    │\xa0\xa0 │\xa0\xa0 └── data.json\n    │   │   └── data_custom.json\n    │   │   └── stops.pkl\n    │   │\n    │\xa0\xa0 ├── models         <-  Helpers, frozen model, models trainer\n    │   │   │                 \n    │\xa0\xa0 │\xa0\xa0 ├── base_model.pkl\n    │\xa0\xa0 │\xa0\xa0 ├── helpers.py\n    │\xa0\xa0 │\xa0\xa0 └── train_model.py\n    │   │\n    │\xa0\xa0 └── visualization  <-  Results oriented visualizations\n    │\xa0\xa0     └── ROC.png\n    │\xa0\xa0     └── ROC_test.png\n    │\n    ├── tests              <-   Path to tests to check models accurance, datatypes, scikit-learn version\n    │\xa0\xa0 ├── __init__.py\n    │\xa0\xa0 ├── conftest.py\n    │   ├── test_basemodel_results.py\n    │\xa0\xa0 ├── test_data.py\n    │   ├── test_scikit_version.py\n    │\xa0\xa0 ├── test_tokenizer.py  \n    │\n    │\n    └── tox.ini            <- tox file to trains base models and run pytests\n\n\n--------\n# Bugs and Errors: 6% Expected Error\n_"All models are wrong, but some are useful"_ There is no magic. Expect the model to make very basic mistakes. To help in training a better model, post an issue with the sentence and expected results, and model results. Because of data limitation, this model performs very well in relationship to products or companies reviews, but limited outside those domain.\n\n\n# TODO\n- [X] Benchmark AFINN and Hisia on Non-Trustpilot data: [comparison results](https://github.com/Proteusiq/hisia/blob/master/notebooks/afinn_hisia_comparison.ipynb)\n- [ ] Use Danish BERT for feature extraction inside of Scikit-Learn Transformers\n- [X] Fix path to the model issue\n- [ ] Remove more useless words (stop_words)\n- [ ] Finish HisiaTrainer\n\n# Retrain and Test: For Developers\nComing Soon\n',
    'author': 'Prayson W. Daniel',
    'author_email': 'praysonwilfred@gmail.com',
    'maintainer': None,
    'maintainer_email': None,
    'url': 'https://github.com/Proteusiq/hisia',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'python_requires': '>=3.8.11,<4.0.0',
}


setup(**setup_kwargs)
